version: "3"

services:
  celery_server:
    env_file: .env
    build:
      context: .
      dockerfile: docker/Dockerfile
    volumes:
      - model_file:/model/torch_script
    environment:
      LEVEL: ${LEVEL}
      REDIS: ${REDIS}
    depends_on:
      - redis

  redis:
    image: redis:latest
    ports:
      - 6379:6379

  triton_server:
    image: nvcr.io/nvidia/tritonserver:22.06-py3
    ports:
      - 8000:8000
      - 8001:8001
      - 8002:8002
    command: ["tritonserver", "--model-store=/model/torch_script", "--model-control-mode=poll", --repository-poll-secs=15]
    volumes:
      - model_file:/model/torch_script
    shm_size: 1g
    ulimits:
      memlock: -1
      stack: 67108864

volumes:
  model_file:
